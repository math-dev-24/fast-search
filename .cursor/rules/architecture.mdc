---
description: Architecture of backend - preconnisation
globs:
alwaysApply: false
---
# FastSearch - Architecture Backend

## Vue d'ensemble

FastSearch utilise une architecture hexagonale (ports et adaptateurs) avec un focus sur la performance multi-threadée et l'optimisation des ressources. Le backend Rust/Tauri est conçu pour gérer efficacement l'indexation et la recherche de millions de fichiers.

## Architecture Hexagonale

### Core Domain (Hexagone Central)

```
src/
├── domain/
│   ├── entities/
│   │   ├── file.rs           # Entité File
│   │   ├── search_query.rs   # Requête de recherche
│   │   └── index_stats.rs    # Statistiques d'indexation
│   ├── repositories/
│   │   ├── file_repository.rs     # Port - Interface repository
│   │   └── search_repository.rs   # Port - Interface recherche
│   ├── services/
│   │   ├── indexing_service.rs    # Service métier indexation
│   │   ├── search_service.rs      # Service métier recherche
│   │   └── file_watcher_service.rs # Service surveillance
│   └── value_objects/
│       ├── file_path.rs      # Chemin de fichier validé
│       ├── file_size.rs      # Taille avec unités
│       └── search_filter.rs  # Filtres de recherche
```

### Ports (Interfaces)

```rust
// Ports primaires (API)
pub trait IndexingPort {
    async fn start_indexing(&self, paths: Vec<PathBuf>) -> Result<(), IndexingError>;
    async fn get_indexing_status(&self) -> IndexingStatus;
    async fn pause_indexing(&self) -> Result<(), IndexingError>;
}

pub trait SearchPort {
    async fn search(&self, query: SearchQuery) -> Result<Vec<File>, SearchError>;
    async fn get_suggestions(&self, partial: String) -> Vec<String>;
}

// Ports secondaires (Infrastructure)
pub trait FileRepositoryPort {
    async fn insert_batch(&self, files: Vec<File>) -> Result<(), RepositoryError>;
    async fn find_by_criteria(&self, criteria: SearchCriteria) -> Result<Vec<File>, RepositoryError>;
    async fn update_file(&self, file: File) -> Result<(), RepositoryError>;
    async fn delete_by_path(&self, path: &Path) -> Result<(), RepositoryError>;
}

pub trait FileSystemPort {
    async fn scan_directory(&self, path: &Path) -> Result<Vec<DirEntry>, ScanError>;
    async fn watch_changes(&self, paths: Vec<PathBuf>) -> Result<ChangeStream, WatchError>;
}
```

### Adaptateurs (Implémentations)

```
src/
├── adapters/
│   ├── primary/           # Adaptateurs entrants
│   │   ├── tauri/
│   │   │   ├── commands.rs     # Commandes Tauri
│   │   │   └── events.rs       # Événements Tauri
│   │   └── api/
│   │       └── rest_handlers.rs # API REST (optionnel)
│   ├── secondary/         # Adaptateurs sortants
│   │   ├── persistence/
│   │   │   ├── sqlite_repository.rs  # Implémentation SQLite
│   │   │   ├── sled_repository.rs    # Implémentation Sled
│   │   │   └── in_memory_repository.rs # Cache mémoire
│   │   └── filesystem/
│   │       ├── walkdir_scanner.rs    # Scanner système fichiers
│   │       └── notify_watcher.rs     # Surveillance changements
│   └── shared/
│       ├── mappers/       # Conversion entre couches
│       └── validators/    # Validation des données
```

## Architecture Multi-threadée

### Thread Pool Architecture

```rust
// Configuration des pools de threads
pub struct ThreadPoolConfig {
    pub indexing_pool_size: usize,    // Threads pour l'indexation
    pub search_pool_size: usize,      // Threads pour la recherche
    pub io_pool_size: usize,          // Threads pour les I/O
    pub cpu_pool_size: usize,         // Threads pour les calculs CPU
}

impl Default for ThreadPoolConfig {
    fn default() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            indexing_pool_size: cpu_count.max(4),
            search_pool_size: cpu_count / 2,
            io_pool_size: cpu_count * 2,
            cpu_pool_size: cpu_count,
        }
    }
}
```

### Stratégie de Parallélisation

#### 1. Pipeline d'Indexation Multi-étapes

```rust
// Pipeline avec channels pour communication inter-threads
pub struct IndexingPipeline {
    // Étape 1: Découverte des fichiers
    scanner_pool: ThreadPool,
    scan_sender: Sender<PathBuf>,
    scan_receiver: Receiver<PathBuf>,
    
    // Étape 2: Traitement des métadonnées
    processor_pool: ThreadPool,
    process_sender: Sender<DirEntry>,
    process_receiver: Receiver<DirEntry>,
    
    // Étape 3: Insertion en base
    inserter_pool: ThreadPool,
    insert_sender: Sender<Vec<File>>,
    insert_receiver: Receiver<Vec<File>>,
    
    // Coordination
    coordinator: Arc<IndexingCoordinator>,
}
```

#### 2. Gestion des Ressources

```rust
// Limitation des ressources système
pub struct ResourceManager {
    // Limitation mémoire
    memory_limit: Arc<AtomicUsize>,
    current_memory: Arc<AtomicUsize>,
    
    // Limitation I/O
    io_semaphore: Arc<Semaphore>,
    
    // Limitation CPU
    cpu_semaphore: Arc<Semaphore>,
    
    // Monitoring
    metrics: Arc<Mutex<ResourceMetrics>>,
}

impl ResourceManager {
    pub async fn acquire_memory(&self, size: usize) -> Result<MemoryGuard, ResourceError> {
        // Attendre si limite mémoire atteinte
        while self.current_memory.load(Ordering::Relaxed) + size > 
              self.memory_limit.load(Ordering::Relaxed) {
            tokio::time::sleep(Duration::from_millis(10)).await;
        }
        
        self.current_memory.fetch_add(size, Ordering::Relaxed);
        Ok(MemoryGuard::new(size, self.current_memory.clone()))
    }
}
```

## Optimisations de Performance

### 1. Stratégies de Cache

```rust
// Cache multi-niveaux
pub struct CacheLayer {
    // L1: Cache mémoire ultra-rapide (LRU)
    l1_cache: Arc<Mutex<LruCache<String, Vec<File>>>>,
    
    // L2: Cache disque compressé
    l2_cache: Arc<SledCache>,
    
    // L3: Index principal
    main_index: Arc<dyn FileRepositoryPort>,
    
    // Statistiques
    cache_stats: Arc<AtomicCacheStats>,
}

impl CacheLayer {
    pub async fn get(&self, key: &str) -> Option<Vec<File>> {
        // Recherche L1
        if let Some(result) = self.l1_cache.lock().await.get(key) {
            self.cache_stats.l1_hits.fetch_add(1, Ordering::Relaxed);
            return Some(result.clone());
        }
        
        // Recherche L2
        if let Some(result) = self.l2_cache.get(key).await {
            self.cache_stats.l2_hits.fetch_add(1, Ordering::Relaxed);
            // Promouvoir en L1
            self.l1_cache.lock().await.put(key.to_string(), result.clone());
            return Some(result);
        }
        
        // Recherche L3 + mise en cache
        if let Ok(result) = self.main_index.find_by_key(key).await {
            self.cache_stats.l3_hits.fetch_add(1, Ordering::Relaxed);
            self.populate_caches(key, &result).await;
            return Some(result);
        }
        
        self.cache_stats.misses.fetch_add(1, Ordering::Relaxed);
        None
    }
}
```

### 2. Optimisations I/O

```rust
// Batch processing pour réduire les syscalls
pub struct BatchProcessor<T> {
    buffer: Vec<T>,
    batch_size: usize,
    flush_interval: Duration,
    processor: Arc<dyn Fn(Vec<T>) -> Result<(), ProcessError> + Send + Sync>,
    last_flush: Instant,
}

impl<T> BatchProcessor<T> {
    pub async fn push(&mut self, item: T) -> Result<(), ProcessError> {
        self.buffer.push(item);
        
        // Flush si batch plein ou timeout
        if self.buffer.len() >= self.batch_size || 
           self.last_flush.elapsed() > self.flush_interval {
            self.flush().await?;
        }
        
        Ok(())
    }
    
    async fn flush(&mut self) -> Result<(), ProcessError> {
        if !self.buffer.is_empty() {
            let batch = std::mem::take(&mut self.buffer);
            (self.processor)(batch)?;
            self.last_flush = Instant::now();
        }
        Ok(())
    }
}
```

### 3. Structures de Données Optimisées

```rust
// Index inversé pour recherche rapide
pub struct InvertedIndex {
    // Terme -> Liste des fichiers
    term_to_files: DashMap<String, RoaringBitmap>,
    
    // ID fichier -> Métadonnées
    file_metadata: DashMap<u32, FileMetadata>,
    
    // Bloomfilter pour existence rapide
    bloom_filter: BloomFilter,
    
    // Statistiques
    stats: IndexStats,
}

// Trie pour autocomplétion
pub struct TrieIndex {
    root: Arc<TrieNode>,
    size: AtomicUsize,
}

// Spatial index pour recherche géographique (si métadonnées EXIF)
pub struct SpatialIndex {
    rtree: RTree<GeomWithData<Point<f64>, u32>>,
}
```

## Gestion des Erreurs et Résilience

### Stratégie d'Erreur

```rust
// Hiérarchie d'erreurs
#[derive(Debug, thiserror::Error)]
pub enum FastSearchError {
    #[error("Erreur d'indexation: {0}")]
    Indexing(#[from] IndexingError),
    
    #[error("Erreur de recherche: {0}")]
    Search(#[from] SearchError),
    
    #[error("Erreur de repository: {0}")]
    Repository(#[from] RepositoryError),
    
    #[error("Erreur système: {0}")]
    System(#[from] SystemError),
}

// Circuit breaker pour résilience
pub struct CircuitBreaker {
    state: Arc<Mutex<CircuitState>>,
    failure_threshold: usize,
    recovery_timeout: Duration,
    failure_count: AtomicUsize,
    last_failure: Arc<Mutex<Option<Instant>>>,
}
```

### Retry et Backoff

```rust
// Stratégie de retry exponentiel
pub struct RetryConfig {
    max_retries: usize,
    base_delay: Duration,
    max_delay: Duration,
    jitter: bool,
}

impl RetryConfig {
    pub async fn retry<F, T, E>(&self, mut operation: F) -> Result<T, E>
    where
        F: FnMut() -> Result<T, E>,
        E: std::fmt::Debug,
    {
        let mut delay = self.base_delay;
        
        for attempt in 0..self.max_retries {
            match operation() {
                Ok(result) => return Ok(result),
                Err(e) => {
                    if attempt == self.max_retries - 1 {
                        return Err(e);
                    }
                    
                    if self.jitter {
                        delay = self.add_jitter(delay);
                    }
                    
                    tokio::time::sleep(delay).await;
                    delay = (delay * 2).min(self.max_delay);
                }
            }
        }
        
        unreachable!()
    }
}
```

## Monitoring et Observabilité

### Métriques de Performance

```rust
// Collecte de métriques
pub struct PerformanceMetrics {
    // Métriques d'indexation
    pub indexing_rate: Arc<AtomicU64>,          // fichiers/seconde
    pub indexing_latency: Arc<AtomicU64>,       // ms moyenne
    pub queue_depth: Arc<AtomicUsize>,          // files d'attente
    
    // Métriques de recherche
    pub search_latency: Arc<AtomicU64>,         // ms moyenne
    pub search_throughput: Arc<AtomicU64>,      // requêtes/seconde
    pub cache_hit_rate: Arc<AtomicU64>,         // % de cache hits
    
    // Métriques système
    pub memory_usage: Arc<AtomicUsize>,         // bytes
    pub cpu_usage: Arc<AtomicU64>,              // % CPU
    pub disk_io: Arc<AtomicU64>,                // bytes/seconde
    
    // Métriques d'erreur
    pub error_rate: Arc<AtomicU64>,             // erreurs/seconde
    pub circuit_breaker_state: Arc<AtomicU8>,   // état du circuit breaker
}

// Collecteur de métriques
pub struct MetricsCollector {
    metrics: Arc<PerformanceMetrics>,
    collection_interval: Duration,
    exporters: Vec<Box<dyn MetricsExporter>>,
}
```

### Logging Structuré

```rust
// Configuration des logs
pub struct LoggingConfig {
    pub level: LevelFilter,
    pub structured: bool,
    pub file_output: Option<PathBuf>,
    pub json_format: bool,
    pub include_thread_id: bool,
    pub include_module_path: bool,
}

// Macros pour logs contextuels
macro_rules! log_indexing {
    ($level:expr, $msg:expr, $($field:ident = $value:expr),*) => {
        log::log!(
            $level,
            "{}: {}",
            "INDEXING",
            format_args!($msg, $($field = $value),*)
        );
    };
}
```

## Configuration et Déploiement

### Configuration Adaptive

```rust
// Configuration auto-adaptative
pub struct AdaptiveConfig {
    // Configuration de base
    base_config: BaseConfig,
    
    // Adaptations runtime
    runtime_adjustments: Arc<Mutex<RuntimeConfig>>,
    
    // Monitoring pour ajustements
    performance_monitor: Arc<PerformanceMonitor>,
}

impl AdaptiveConfig {
    pub async fn optimize_for_system(&mut self) -> Result<(), ConfigError> {
        let system_info = self.get_system_info().await?;
        
        // Ajuster les pools de threads
        self.adjust_thread_pools(&system_info).await?;
        
        // Ajuster les limites mémoire
        self.adjust_memory_limits(&system_info).await?;
        
        // Ajuster les stratégies de cache
        self.adjust_cache_strategy(&system_info).await?;
        
        Ok(())
    }
}
```

### Profils de Déploiement

```rust
// Profils optimisés pour différents cas d'usage
pub enum DeploymentProfile {
    Development {
        debug_mode: bool,
        hot_reload: bool,
        verbose_logging: bool,
    },
    Production {
        performance_optimized: bool,
        minimal_logging: bool,
        metrics_enabled: bool,
    },
    LowResource {
        memory_limit: usize,
        reduced_threads: bool,
        simple_cache: bool,
    },
    HighPerformance {
        max_threads: bool,
        aggressive_caching: bool,
        preload_indexes: bool,
    },
}
```

## Tests et Benchmarks

### Stratégie de Tests

```rust
// Tests de performance
#[cfg(test)]
mod performance_tests {
    use super::*;
    use criterion::Criterion;
    
    #[bench]
    fn bench_indexing_performance(c: &mut Criterion) {
        let indexer = setup_indexer();
        let test_files = generate_test_files(100_000);
        
        c.bench_function("index_100k_files", |b| {
            b.iter(|| {
                let _ = indexer.index_files(&test_files);
            })
        });
    }
    
    #[bench]
    fn bench_search_performance(c: &mut Criterion) {
        let searcher = setup_searcher_with_index();
        
        c.bench_function("search_common_terms", |b| {
            b.iter(|| {
                let _ = searcher.search("test.txt");
            })
        });
    }
}
```

## Migration et Évolution

### Stratégie de Migration

```rust
// Gestion des versions de schéma
pub struct SchemaManager {
    current_version: u32,
    migrations: Vec<Box<dyn Migration>>,
}

pub trait Migration {
    fn version(&self) -> u32;
    fn up(&self, db: &mut dyn Database) -> Result<(), MigrationError>;
    fn down(&self, db: &mut dyn Database) -> Result<(), MigrationError>;
}
```

Cette architecture garantit :
- **Scalabilité** : Gestion efficace de millions de fichiers
- **Performance** : Optimisations multi-threadées et de cache
- **Maintenabilité** : Séparation claire des responsabilités
- **Extensibilité** : Architecture modulaire avec ports/adaptateurs
- **Résilience** : Gestion d'erreurs et récupération automatique